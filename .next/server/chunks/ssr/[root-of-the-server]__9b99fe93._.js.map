{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 13, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/components/MotionSelector.tsx"],"sourcesContent":["'use client';\n\nimport React from 'react';\n\n// Define the types for capture modes\nexport type CaptureType = 'face' | 'pose' | 'hands';\n\ninterface MotionSelectorProps {\n  onSelect: (type: CaptureType) => void;\n}\n\nconst MotionSelector: React.FC<MotionSelectorProps> = ({ onSelect }) => {\n  const captureOptions: { type: CaptureType; label: string; description: string }[] = [\n    {\n      type: 'face',\n      label: 'Face Capture',\n      description: 'Track facial landmarks for expressions.',\n    },\n    {\n      type: 'pose',\n      label: 'Body Pose Capture',\n      description: 'Track full-body pose for character animation.',\n    },\n    {\n      type: 'hands',\n      label: 'Hand Pose Capture',\n      description: 'Track detailed hand and finger movements.',\n    },\n  ];\n\n  return (\n    <div className=\"flex flex-col items-center justify-center space-y-8\">\n      <h1 className=\"text-4xl font-bold\">Choose Capture Type</h1>\n      <div className=\"grid grid-cols-1 md:grid-cols-3 gap-6 text-center\">\n        {captureOptions.map((option) => (\n          <button\n            key={option.type}\n            onClick={() => onSelect(option.type)}\n            className=\"p-6 border rounded-lg hover:bg-neutral-100 dark:hover:bg-neutral-800/30 transition-colors\"\n          >\n            <h2 className=\"text-2xl font-semibold mb-2\">{option.label}</h2>\n            <p className=\"text-sm text-neutral-500 dark:text-neutral-400\">{option.description}</p>\n          </button>\n        ))}\n      </div>\n    </div>\n  );\n};\n\nexport default MotionSelector;"],"names":[],"mappings":";;;;AAAA;;AAWA,MAAM,iBAAgD,CAAC,EAAE,QAAQ,EAAE;IACjE,MAAM,iBAA8E;QAClF;YACE,MAAM;YACN,OAAO;YACP,aAAa;QACf;QACA;YACE,MAAM;YACN,OAAO;YACP,aAAa;QACf;QACA;YACE,MAAM;YACN,OAAO;YACP,aAAa;QACf;KACD;IAED,qBACE,8OAAC;QAAI,WAAU;;0BACb,8OAAC;gBAAG,WAAU;0BAAqB;;;;;;0BACnC,8OAAC;gBAAI,WAAU;0BACZ,eAAe,GAAG,CAAC,CAAC,uBACnB,8OAAC;wBAEC,SAAS,IAAM,SAAS,OAAO,IAAI;wBACnC,WAAU;;0CAEV,8OAAC;gCAAG,WAAU;0CAA+B,OAAO,KAAK;;;;;;0CACzD,8OAAC;gCAAE,WAAU;0CAAkD,OAAO,WAAW;;;;;;;uBAL5E,OAAO,IAAI;;;;;;;;;;;;;;;;AAW5B;uCAEe","debugId":null}},
    {"offset": {"line": 93, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/components/TunnelPairer.tsx"],"sourcesContent":["'use client';\n\nimport React, { useState } from 'react';\n\n// Define the possible connection statuses for the tunnel\nexport type TunnelStatus = 'disconnected' | 'connecting' | 'connected' | 'error';\n\ninterface TunnelPairerProps {\n  status: TunnelStatus;\n  error?: string | null;\n  onConnect: (url: string) => void;\n  onDisconnect: () => void;\n}\n\nconst TunnelPairer: React.FC<TunnelPairerProps> = ({\n  status,\n  error,\n  onConnect,\n  onDisconnect,\n}) => {\n  const [url, setUrl] = useState('');\n\n  const isConnected = status === 'connected';\n  const isConnecting = status === 'connecting';\n\n  const handleConnect = (e: React.FormEvent) => {\n    e.preventDefault();\n    if (url.trim()) {\n      onConnect(url.trim());\n    }\n  };\n\n  return (\n    <div className=\"p-6 border rounded-lg w-full max-w-md shadow-md bg-white dark:bg-neutral-900\">\n      <h2 className=\"text-xl font-semibold mb-4\">Blender Tunnel Connection</h2>\n\n      {isConnected ? (\n        <div className=\"text-center\">\n          <p className=\"text-green-500 mb-4 font-medium\">Status: Connected</p>\n          <button\n            onClick={onDisconnect}\n            className=\"w-full px-4 py-2 bg-red-600 text-white rounded-lg hover:bg-red-700 transition-colors\"\n          >\n            Disconnect\n          </button>\n        </div>\n      ) : (\n        <form onSubmit={handleConnect} className=\"space-y-4\">\n          <div>\n            <label htmlFor=\"tunnel-url\" className=\"block text-sm font-medium mb-1\">\n              Paste Tunnel URL\n            </label>\n            <input\n              id=\"tunnel-url\"\n              type=\"text\"\n              value={url}\n              onChange={(e) => setUrl(e.target.value)}\n              placeholder=\"wss://your-tunnel-url.io\"\n              disabled={isConnecting}\n              className=\"w-full px-3 py-2 border border-input rounded-lg bg-background text-foreground focus:ring-ring focus:ring-2 focus:outline-none\"\n            />\n          </div>\n          <button\n            type=\"submit\"\n            disabled={isConnecting || !url.trim()}\n            className=\"w-full px-4 py-2 bg-blue-600 text-white rounded-lg disabled:bg-gray-400 transition-colors\"\n          >\n            {isConnecting ? 'Connecting...' : 'Connect'}\n          </button>\n          {error && <p className=\"text-red-500 text-sm mt-2\">{error}</p>}\n        </form>\n      )}\n    </div>\n  );\n};\n\nexport default TunnelPairer;"],"names":[],"mappings":";;;;AAEA;AAFA;;;AAcA,MAAM,eAA4C,CAAC,EACjD,MAAM,EACN,KAAK,EACL,SAAS,EACT,YAAY,EACb;IACC,MAAM,CAAC,KAAK,OAAO,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAE;IAE/B,MAAM,cAAc,WAAW;IAC/B,MAAM,eAAe,WAAW;IAEhC,MAAM,gBAAgB,CAAC;QACrB,EAAE,cAAc;QAChB,IAAI,IAAI,IAAI,IAAI;YACd,UAAU,IAAI,IAAI;QACpB;IACF;IAEA,qBACE,8OAAC;QAAI,WAAU;;0BACb,8OAAC;gBAAG,WAAU;0BAA6B;;;;;;YAE1C,4BACC,8OAAC;gBAAI,WAAU;;kCACb,8OAAC;wBAAE,WAAU;kCAAkC;;;;;;kCAC/C,8OAAC;wBACC,SAAS;wBACT,WAAU;kCACX;;;;;;;;;;;yEAKH,8OAAC;gBAAK,UAAU;gBAAe,WAAU;;kCACvC,8OAAC;;0CACC,8OAAC;gCAAM,SAAQ;gCAAa,WAAU;0CAAiC;;;;;;0CAGvE,8OAAC;gCACC,IAAG;gCACH,MAAK;gCACL,OAAO;gCACP,UAAU,CAAC,IAAM,OAAO,EAAE,MAAM,CAAC,KAAK;gCACtC,aAAY;gCACZ,UAAU;gCACV,WAAU;;;;;;;;;;;;kCAGd,8OAAC;wBACC,MAAK;wBACL,UAAU,gBAAgB,CAAC,IAAI,IAAI;wBACnC,WAAU;kCAET,eAAe,kBAAkB;;;;;;oBAEnC,uBAAS,8OAAC;wBAAE,WAAU;kCAA6B;;;;;;;;;;;;;;;;;;AAK9D;uCAEe","debugId":null}},
    {"offset": {"line": 217, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/services/motion/capture.ts"],"sourcesContent":["import {\n  FaceLandmarker,\n  PoseLandmarker,\n  HandLandmarker,\n  FilesetResolver,\n} from '@mediapipe/tasks-vision';\nimport { CaptureType } from '@/components/MotionSelector';\n\n// A union type for the possible landmarker instances\nexport type MotionLandmarker = FaceLandmarker | PoseLandmarker | HandLandmarker;\n\n// Base path for the MediaPipe models hosted by Google\nconst BASE_MODEL_PATH = 'https://storage.googleapis.com/mediapipe-models/';\n\n/**\n * Creates and initializes a MediaPipe Landmarker based on the capture type.\n * This function handles loading the appropriate model and configuring it for\n * video-based motion capture.\n *\n * @param captureType The type of motion to capture ('face', 'pose', 'hands').\n * @returns A promise that resolves to the initialized landmarker instance.\n */\nexport const createMotionLandmarker = async (\n  captureType: CaptureType\n): Promise<MotionLandmarker> => {\n  const vision = await FilesetResolver.forVisionTasks(\n    // Path to the WASM files for the vision tasks\n    'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'\n  );\n\n  switch (captureType) {\n    case 'face':\n      return await FaceLandmarker.createFromOptions(vision, {\n        baseOptions: {\n          modelAssetPath: `${BASE_MODEL_PATH}face_landmarker/face_landmarker/float16/1/face_landmarker.task`,\n          delegate: 'GPU',\n        },\n        outputFaceBlendshapes: true, // Required for expression tracking\n        runningMode: 'VIDEO',\n        numFaces: 1, // Track a single face\n      });\n    case 'pose':\n      return await PoseLandmarker.createFromOptions(vision, {\n        baseOptions: {\n          modelAssetPath: `${BASE_MODEL_PATH}pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numPoses: 1, // Track a single person\n      });\n    case 'hands':\n      return await HandLandmarker.createFromOptions(vision, {\n        baseOptions: {\n          modelAssetPath: `${BASE_MODEL_PATH}hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,\n          delegate: 'GPU',\n        },\n        runningMode: 'VIDEO',\n        numHands: 2, // Track both hands\n      });\n    default:\n      // This should never be reached if CaptureType is used correctly\n      throw new Error(`Unsupported capture type: ${captureType}`);\n  }\n};"],"names":[],"mappings":";;;AAAA;;AAWA,sDAAsD;AACtD,MAAM,kBAAkB;AAUjB,MAAM,yBAAyB,OACpC;IAEA,MAAM,SAAS,MAAM,gKAAA,CAAA,kBAAe,CAAC,cAAc,CACjD,8CAA8C;IAC9C;IAGF,OAAQ;QACN,KAAK;YACH,OAAO,MAAM,gKAAA,CAAA,iBAAc,CAAC,iBAAiB,CAAC,QAAQ;gBACpD,aAAa;oBACX,gBAAgB,GAAG,gBAAgB,8DAA8D,CAAC;oBAClG,UAAU;gBACZ;gBACA,uBAAuB;gBACvB,aAAa;gBACb,UAAU;YACZ;QACF,KAAK;YACH,OAAO,MAAM,gKAAA,CAAA,iBAAc,CAAC,iBAAiB,CAAC,QAAQ;gBACpD,aAAa;oBACX,gBAAgB,GAAG,gBAAgB,wEAAwE,CAAC;oBAC5G,UAAU;gBACZ;gBACA,aAAa;gBACb,UAAU;YACZ;QACF,KAAK;YACH,OAAO,MAAM,gKAAA,CAAA,iBAAc,CAAC,iBAAiB,CAAC,QAAQ;gBACpD,aAAa;oBACX,gBAAgB,GAAG,gBAAgB,8DAA8D,CAAC;oBAClG,UAAU;gBACZ;gBACA,aAAa;gBACb,UAAU;YACZ;QACF;YACE,gEAAgE;YAChE,MAAM,IAAI,MAAM,CAAC,0BAA0B,EAAE,aAAa;IAC9D;AACF","debugId":null}},
    {"offset": {"line": 265, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/hooks/useMotionCapture.ts"],"sourcesContent":["'use client';\n\nimport { useState, useRef, useCallback, useEffect } from 'react';\nimport { DrawingUtils } from '@mediapipe/drawing_utils';\nimport {\n  createMotionLandmarker,\n  MotionLandmarker,\n} from '@/services/motion/capture';\nimport { CaptureType, InputSourceType } from '@/components/MotionSelector';\nimport {\n  FaceLandmarker,\n  HandLandmarker,\n  PoseLandmarker,\n  NormalizedLandmark,\n} from '@mediapipe/tasks-vision';\n// This will eventually hold the structured data from MediaPipe.\nexport type MotionData = any;\n// TODO: Add DrawingUtils to visualize the landmarks on the canvas.\n\nexport interface UseMotionCaptureProps {\n  captureType: CaptureType | null;\n  inputSource: InputSourceType;\n  videoUrl?: string;\n  onData?: (data: MotionData) => void;\n}\n\nexport const useMotionCapture = ({ captureType, onData }: UseMotionCaptureProps) => {\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n\n  const [isCameraOn, setIsCameraOn] = useState(false);\n  const [isProcessing, setIsProcessing] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n\n  const drawingUtilsRef = useRef<DrawingUtils | null>(null);\n  // A ref to hold the MediaPipe landmarker instance.\n  const landmarkerRef = useRef<MotionLandmarker | null>(null);\n  // A ref to hold the animation frame request ID.\n  const animationFrameId = useRef<number | null>(null);\n\n  /**\n   * Stops the video stream and cleans up resources.\n   */\n  const stopCapture = useCallback(() => {\n    if (animationFrameId.current) {\n      cancelAnimationFrame(animationFrameId.current);\n      animationFrameId.current = null;\n    }\n    setIsCameraOn(false);\n\n    const video = videoRef.current;\n    if (!video) return;\n\n    // Stop webcam stream if it exists\n    if (video.srcObject) {\n      const stream = video.srcObject as MediaStream;\n      stream.getTracks().forEach((track) => track.stop());\n      video.srcObject = null;\n    }\n\n    // Reset video element for file source\n    if (video.src) {\n      video.pause();\n      video.removeAttribute('src'); // More robust than video.src = ''\n      video.load(); // Resets the video element\n    }\n  }, [videoRef]);\n\n  /**\n   * The main prediction loop.\n   */\n  const predictVideoFrame = useCallback(() => {\n    const video = videoRef.current;\n    const landmarker = landmarkerRef.current;\n    const canvas = canvasRef.current;\n    const drawingUtils = drawingUtilsRef.current;\n\n    // Ensure everything is ready for prediction.\n    if (!video || !landmarker || !canvas || !drawingUtils || video.paused || video.ended) {\n      return;\n    }\n\n    const canvasCtx = canvas.getContext('2d');\n    if (!canvasCtx) return;\n\n    // Use performance.now() for timestamping, as required by MediaPipe.\n    const startTimeMs = performance.now();\n    const results = landmarker.detectForVideo(video, startTimeMs);\n\n    // Clear the canvas and draw the new results.\n    canvasCtx.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (results && onData) {\n      // Pass the raw data to the callback.\n      onData(results);\n\n      // Draw Pose landmarks\n      if (results.landmarks && captureType === 'pose') {\n        for (const landmarks of results.landmarks as NormalizedLandmark[][]) {\n          drawingUtils.drawConnectors(landmarks, PoseLandmarker.POSE_CONNECTIONS, { color: '#00FF00', lineWidth: 4 });\n          drawingUtils.drawLandmarks(landmarks, { color: '#FF0000', radius: 6 });\n        }\n      }\n      // Draw Hand landmarks\n      if (results.landmarks && captureType === 'hands') {\n        for (const landmarks of results.landmarks as NormalizedLandmark[][]) {\n          drawingUtils.drawConnectors(landmarks, HandLandmarker.HAND_CONNECTIONS, { color: '#00CCFF', lineWidth: 5 });\n          drawingUtils.drawLandmarks(landmarks, { color: '#FF00FF', lineWidth: 2 });\n        }\n      }\n      // Draw Face landmarks\n      if (results.landmarks && captureType === 'face') {\n        for (const landmarks of results.landmarks as NormalizedLandmark[][]) {\n          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_TESSELATION, { color: '#C0C0C070', lineWidth: 1 });\n          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_RIGHT_EYE, { color: '#FF3030' });\n          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_RIGHT_EYEBROW, { color: '#FF3030' });\n          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LEFT_EYE, { color: '#30FF30' });\n          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LEFT_EYEBROW, { color: '#30FF30' });\n          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_FACE_OVAL, { color: '#E0E0E0' });\n          drawingUtils.drawConnectors(landmarks, FaceLandmarker.FACE_LANDMARKS_LIPS, { color: '#E0E0E0' });\n        }\n      }\n    }\n\n    // Continue the loop.\n    animationFrameId.current = requestAnimationFrame(predictVideoFrame);\n  }, [videoRef, canvasRef, onData, captureType]);\n\n  /**\n   * Initializes the MediaPipe landmarker when the capture type changes.\n   */\n  useEffect(() => {\n    if (!captureType) {\n      if (isCameraOn) stopCapture();\n      return;\n    }\n\n    const initialize = async () => {\n      setError(null);\n      setIsProcessing(true);\n      try {\n        const landmarker = await createMotionLandmarker(captureType);\n        landmarkerRef.current = landmarker;\n        // Initialize DrawingUtils\n        const canvasCtx = canvasRef.current?.getContext('2d');\n        if (canvasCtx) {\n          drawingUtilsRef.current = new DrawingUtils(canvasCtx);\n        }\n      } catch (e) {\n        console.error(e);\n        const errorMessage = e instanceof Error ? e.message : String(e);\n        setError(`Failed to initialize MediaPipe: ${errorMessage}`);\n      } finally {\n        setIsProcessing(false);\n      }\n    };\n\n    initialize();\n\n    // Cleanup on component unmount or when captureType changes.\n    return () => {\n      landmarkerRef.current?.close();\n      landmarkerRef.current = null;\n      stopCapture();\n    };\n  }, [captureType, stopCapture]);\n\n  /**\n   * Starts the camera feed. The prediction loop will be triggered\n   * from here once the video is playing.\n   */\n  const startCapture = useCallback(async () => {\n    if (!landmarkerRef.current) {\n      setError('Landmarker is not initialized. Please wait or select a type.');\n      return;\n    }\n    if (!videoRef.current) {\n      setError('Video element is not available.');\n      return;\n    }\n\n    setError(null);\n\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({ video: true });\n      videoRef.current.srcObject = stream;\n      // Set up canvas dimensions once video is ready.\n      videoRef.current.onloadedmetadata = () => {\n        if (videoRef.current && canvasRef.current) {\n          canvasRef.current.width = videoRef.current.videoWidth;\n          canvasRef.current.height = videoRef.current.videoHeight;\n        }\n        setIsCameraOn(true);\n        predictWebcam(); // Start the prediction loop\n      };\n    } catch (e) {\n      setError('Could not access webcam. Please grant permission and try again.');\n    }\n  }, [predictWebcam]);\n\n  return {\n    videoRef,\n    canvasRef,\n    isCameraOn,\n    isProcessing,\n    error,\n    startCapture,\n    stopCapture,\n  };\n};"],"names":[],"mappings":";;;AAEA;AACA;AACA;AAKA;AATA;;;;;AA0BO,MAAM,mBAAmB,CAAC,EAAE,WAAW,EAAE,MAAM,EAAyB;IAC7E,MAAM,WAAW,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAAoB;IAC1C,MAAM,YAAY,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAAqB;IAE5C,MAAM,CAAC,YAAY,cAAc,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAE;IAC7C,MAAM,CAAC,cAAc,gBAAgB,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAE;IACjD,MAAM,CAAC,OAAO,SAAS,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAiB;IAElD,MAAM,kBAAkB,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAAuB;IACpD,mDAAmD;IACnD,MAAM,gBAAgB,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAA2B;IACtD,gDAAgD;IAChD,MAAM,mBAAmB,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAAiB;IAE/C;;GAEC,GACD,MAAM,cAAc,CAAA,GAAA,qMAAA,CAAA,cAAW,AAAD,EAAE;QAC9B,IAAI,iBAAiB,OAAO,EAAE;YAC5B,qBAAqB,iBAAiB,OAAO;YAC7C,iBAAiB,OAAO,GAAG;QAC7B;QACA,cAAc;QAEd,MAAM,QAAQ,SAAS,OAAO;QAC9B,IAAI,CAAC,OAAO;QAEZ,kCAAkC;QAClC,IAAI,MAAM,SAAS,EAAE;YACnB,MAAM,SAAS,MAAM,SAAS;YAC9B,OAAO,SAAS,GAAG,OAAO,CAAC,CAAC,QAAU,MAAM,IAAI;YAChD,MAAM,SAAS,GAAG;QACpB;QAEA,sCAAsC;QACtC,IAAI,MAAM,GAAG,EAAE;YACb,MAAM,KAAK;YACX,MAAM,eAAe,CAAC,QAAQ,kCAAkC;YAChE,MAAM,IAAI,IAAI,2BAA2B;QAC3C;IACF,GAAG;QAAC;KAAS;IAEb;;GAEC,GACD,MAAM,oBAAoB,CAAA,GAAA,qMAAA,CAAA,cAAW,AAAD,EAAE;QACpC,MAAM,QAAQ,SAAS,OAAO;QAC9B,MAAM,aAAa,cAAc,OAAO;QACxC,MAAM,SAAS,UAAU,OAAO;QAChC,MAAM,eAAe,gBAAgB,OAAO;QAE5C,6CAA6C;QAC7C,IAAI,CAAC,SAAS,CAAC,cAAc,CAAC,UAAU,CAAC,gBAAgB,MAAM,MAAM,IAAI,MAAM,KAAK,EAAE;YACpF;QACF;QAEA,MAAM,YAAY,OAAO,UAAU,CAAC;QACpC,IAAI,CAAC,WAAW;QAEhB,oEAAoE;QACpE,MAAM,cAAc,YAAY,GAAG;QACnC,MAAM,UAAU,WAAW,cAAc,CAAC,OAAO;QAEjD,6CAA6C;QAC7C,UAAU,SAAS,CAAC,GAAG,GAAG,OAAO,KAAK,EAAE,OAAO,MAAM;QAErD,IAAI,WAAW,QAAQ;YACrB,qCAAqC;YACrC,OAAO;YAEP,sBAAsB;YACtB,IAAI,QAAQ,SAAS,IAAI,gBAAgB,QAAQ;gBAC/C,KAAK,MAAM,aAAa,QAAQ,SAAS,CAA4B;oBACnE,aAAa,cAAc,CAAC,WAAW,gKAAA,CAAA,iBAAc,CAAC,gBAAgB,EAAE;wBAAE,OAAO;wBAAW,WAAW;oBAAE;oBACzG,aAAa,aAAa,CAAC,WAAW;wBAAE,OAAO;wBAAW,QAAQ;oBAAE;gBACtE;YACF;YACA,sBAAsB;YACtB,IAAI,QAAQ,SAAS,IAAI,gBAAgB,SAAS;gBAChD,KAAK,MAAM,aAAa,QAAQ,SAAS,CAA4B;oBACnE,aAAa,cAAc,CAAC,WAAW,gKAAA,CAAA,iBAAc,CAAC,gBAAgB,EAAE;wBAAE,OAAO;wBAAW,WAAW;oBAAE;oBACzG,aAAa,aAAa,CAAC,WAAW;wBAAE,OAAO;wBAAW,WAAW;oBAAE;gBACzE;YACF;YACA,sBAAsB;YACtB,IAAI,QAAQ,SAAS,IAAI,gBAAgB,QAAQ;gBAC/C,KAAK,MAAM,aAAa,QAAQ,SAAS,CAA4B;oBACnE,aAAa,cAAc,CAAC,WAAW,gKAAA,CAAA,iBAAc,CAAC,0BAA0B,EAAE;wBAAE,OAAO;wBAAa,WAAW;oBAAE;oBACrH,aAAa,cAAc,CAAC,WAAW,gKAAA,CAAA,iBAAc,CAAC,wBAAwB,EAAE;wBAAE,OAAO;oBAAU;oBACnG,aAAa,cAAc,CAAC,WAAW,gKAAA,CAAA,iBAAc,CAAC,4BAA4B,EAAE;wBAAE,OAAO;oBAAU;oBACvG,aAAa,cAAc,CAAC,WAAW,gKAAA,CAAA,iBAAc,CAAC,uBAAuB,EAAE;wBAAE,OAAO;oBAAU;oBAClG,aAAa,cAAc,CAAC,WAAW,gKAAA,CAAA,iBAAc,CAAC,2BAA2B,EAAE;wBAAE,OAAO;oBAAU;oBACtG,aAAa,cAAc,CAAC,WAAW,gKAAA,CAAA,iBAAc,CAAC,wBAAwB,EAAE;wBAAE,OAAO;oBAAU;oBACnG,aAAa,cAAc,CAAC,WAAW,gKAAA,CAAA,iBAAc,CAAC,mBAAmB,EAAE;wBAAE,OAAO;oBAAU;gBAChG;YACF;QACF;QAEA,qBAAqB;QACrB,iBAAiB,OAAO,GAAG,sBAAsB;IACnD,GAAG;QAAC;QAAU;QAAW;QAAQ;KAAY;IAE7C;;GAEC,GACD,CAAA,GAAA,qMAAA,CAAA,YAAS,AAAD,EAAE;QACR,IAAI,CAAC,aAAa;YAChB,IAAI,YAAY;YAChB;QACF;QAEA,MAAM,aAAa;YACjB,SAAS;YACT,gBAAgB;YAChB,IAAI;gBACF,MAAM,aAAa,MAAM,CAAA,GAAA,6HAAA,CAAA,yBAAsB,AAAD,EAAE;gBAChD,cAAc,OAAO,GAAG;gBACxB,0BAA0B;gBAC1B,MAAM,YAAY,UAAU,OAAO,EAAE,WAAW;gBAChD,IAAI,WAAW;oBACb,gBAAgB,OAAO,GAAG,IAAI,6JAAA,CAAA,eAAY,CAAC;gBAC7C;YACF,EAAE,OAAO,GAAG;gBACV,QAAQ,KAAK,CAAC;gBACd,MAAM,eAAe,aAAa,QAAQ,EAAE,OAAO,GAAG,OAAO;gBAC7D,SAAS,CAAC,gCAAgC,EAAE,cAAc;YAC5D,SAAU;gBACR,gBAAgB;YAClB;QACF;QAEA;QAEA,4DAA4D;QAC5D,OAAO;YACL,cAAc,OAAO,EAAE;YACvB,cAAc,OAAO,GAAG;YACxB;QACF;IACF,GAAG;QAAC;QAAa;KAAY;IAE7B;;;GAGC,GACD,MAAM,eAAe,CAAA,GAAA,qMAAA,CAAA,cAAW,AAAD,EAAE;QAC/B,IAAI,CAAC,cAAc,OAAO,EAAE;YAC1B,SAAS;YACT;QACF;QACA,IAAI,CAAC,SAAS,OAAO,EAAE;YACrB,SAAS;YACT;QACF;QAEA,SAAS;QAET,IAAI;YACF,MAAM,SAAS,MAAM,UAAU,YAAY,CAAC,YAAY,CAAC;gBAAE,OAAO;YAAK;YACvE,SAAS,OAAO,CAAC,SAAS,GAAG;YAC7B,gDAAgD;YAChD,SAAS,OAAO,CAAC,gBAAgB,GAAG;gBAClC,IAAI,SAAS,OAAO,IAAI,UAAU,OAAO,EAAE;oBACzC,UAAU,OAAO,CAAC,KAAK,GAAG,SAAS,OAAO,CAAC,UAAU;oBACrD,UAAU,OAAO,CAAC,MAAM,GAAG,SAAS,OAAO,CAAC,WAAW;gBACzD;gBACA,cAAc;gBACd,iBAAiB,4BAA4B;YAC/C;QACF,EAAE,OAAO,GAAG;YACV,SAAS;QACX;IACF,GAAG;QAAC;KAAc;IAElB,OAAO;QACL;QACA;QACA;QACA;QACA;QACA;QACA;IACF;AACF","debugId":null}},
    {"offset": {"line": 480, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/lib/json-export.ts"],"sourcesContent":["import { MotionData } from '@/hooks/useMotionCapture';\nimport { CaptureType } from '@/components/MotionSelector';\n\n// Define a structured format for the exported data, including schema versioning.\nexport interface MotionDataPacket {\n  schemaVersion: string;\n  captureType: CaptureType;\n  timestamp: string;\n  data: MotionData;\n}\n\nconst SCHEMA_VERSION = '1.0.0';\n\n/**\n * Creates a structured data packet for export or transmission.\n */\nexport const createMotionDataPacket = (\n  motionData: MotionData,\n  captureType: CaptureType\n): MotionDataPacket => ({\n  schemaVersion: SCHEMA_VERSION,\n  captureType: captureType,\n  timestamp: new Date().toISOString(),\n  data: motionData,\n});\n\n/**\n * Saves the captured motion data to a JSON file and triggers a browser download.\n *\n * @param motionData The raw motion data from MediaPipe.\n * @param captureType The type of capture that was performed.\n */\nexport const downloadMotionDataAsJson = (\n  motionData: MotionData,\n  captureType: CaptureType\n): void => {\n  const exportObject = createMotionDataPacket(motionData, captureType);\n  const jsonString = JSON.stringify(exportObject, null, 2);\n  const blob = new Blob([jsonString], { type: 'application/json' });\n  const url = URL.createObjectURL(blob);\n\n  const a = document.createElement('a');\n  a.href = url;\n  a.download = `gaomotion_${captureType}_${new Date().getTime()}.json`;\n  document.body.appendChild(a);\n  a.click();\n  document.body.removeChild(a);\n  URL.revokeObjectURL(url);\n};\n\n/**\n * Saves the captured motion data to the browser's localStorage.\n */\nexport const saveMotionDataToLocalStorage = (\n  motionData: MotionData,\n  captureType: CaptureType,\n  key: string = 'latestMotionData'\n): void => {\n  try {\n    const exportObject = createMotionDataPacket(motionData, captureType);\n    const jsonString = JSON.stringify(exportObject);\n    localStorage.setItem(key, jsonString);\n  } catch (error) {\n    console.error('Failed to save motion data to localStorage:', error);\n  }\n};"],"names":[],"mappings":";;;;;AAWA,MAAM,iBAAiB;AAKhB,MAAM,yBAAyB,CACpC,YACA,cACqB,CAAC;QACtB,eAAe;QACf,aAAa;QACb,WAAW,IAAI,OAAO,WAAW;QACjC,MAAM;IACR,CAAC;AAQM,MAAM,2BAA2B,CACtC,YACA;IAEA,MAAM,eAAe,uBAAuB,YAAY;IACxD,MAAM,aAAa,KAAK,SAAS,CAAC,cAAc,MAAM;IACtD,MAAM,OAAO,IAAI,KAAK;QAAC;KAAW,EAAE;QAAE,MAAM;IAAmB;IAC/D,MAAM,MAAM,IAAI,eAAe,CAAC;IAEhC,MAAM,IAAI,SAAS,aAAa,CAAC;IACjC,EAAE,IAAI,GAAG;IACT,EAAE,QAAQ,GAAG,CAAC,UAAU,EAAE,YAAY,CAAC,EAAE,IAAI,OAAO,OAAO,GAAG,KAAK,CAAC;IACpE,SAAS,IAAI,CAAC,WAAW,CAAC;IAC1B,EAAE,KAAK;IACP,SAAS,IAAI,CAAC,WAAW,CAAC;IAC1B,IAAI,eAAe,CAAC;AACtB;AAKO,MAAM,+BAA+B,CAC1C,YACA,aACA,MAAc,kBAAkB;IAEhC,IAAI;QACF,MAAM,eAAe,uBAAuB,YAAY;QACxD,MAAM,aAAa,KAAK,SAAS,CAAC;QAClC,aAAa,OAAO,CAAC,KAAK;IAC5B,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,+CAA+C;IAC/D;AACF","debugId":null}},
    {"offset": {"line": 522, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/components/RigMapper.tsx"],"sourcesContent":["'use client';\n\nimport React from 'react';\nimport { RigPose } from '@/types/rig';\n\n/**\n * A component to visualize the live rig pose data being generated.\n */\nconst RigMapper: React.FC<{ pose: RigPose | null }> = ({ pose }) => {\n  return (\n    <div className=\"p-6 border rounded-lg w-full max-w-md shadow-md bg-white dark:bg-neutral-900\">\n      <h2 className=\"text-xl font-semibold mb-4\">Rig Mapper (Live Data)</h2>\n      <div className=\"space-y-2 text-sm text-neutral-600 dark:text-neutral-400\">\n        {pose ? (\n          <pre className=\"text-xs bg-neutral-100 dark:bg-neutral-800 p-2 rounded-md overflow-x-auto max-h-64\">\n            <code>{JSON.stringify(pose, null, 2)}</code>\n          </pre>\n        ) : (\n          <div className=\"text-center py-10\">\n            <p>Waiting for motion data...</p>\n            <p className=\"text-xs text-neutral-500 mt-2\">\n              Start the camera to see live pose data here.\n            </p>\n          </div>\n        )}\n      </div>\n    </div>\n  );\n};\n\nexport default RigMapper;"],"names":[],"mappings":";;;;AAAA;;AAKA;;CAEC,GACD,MAAM,YAAgD,CAAC,EAAE,IAAI,EAAE;IAC7D,qBACE,8OAAC;QAAI,WAAU;;0BACb,8OAAC;gBAAG,WAAU;0BAA6B;;;;;;0BAC3C,8OAAC;gBAAI,WAAU;0BACZ,qBACC,8OAAC;oBAAI,WAAU;8BACb,cAAA,8OAAC;kCAAM,KAAK,SAAS,CAAC,MAAM,MAAM;;;;;;;;;;6EAGpC,8OAAC;oBAAI,WAAU;;sCACb,8OAAC;sCAAE;;;;;;sCACH,8OAAC;4BAAE,WAAU;sCAAgC;;;;;;;;;;;;;;;;;;;;;;;AAQzD;uCAEe","debugId":null}},
    {"offset": {"line": 598, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/services/motion/mapper.ts"],"sourcesContent":["import { MotionData } from '@/hooks/useMotionCapture';\nimport { RigPose } from '@/types/rig';\nimport { Quaternion, Vector3, Matrix4 } from 'three';\n\n// MediaPipe Pose Landmark indices for easy access\nconst POSE_LANDMARKS = {\n  LEFT_SHOULDER: 11,\n  RIGHT_SHOULDER: 12,\n  LEFT_ELBOW: 13,\n  RIGHT_ELBOW: 14,\n  LEFT_WRIST: 15,\n  RIGHT_WRIST: 16,\n  LEFT_HIP: 23,\n  RIGHT_HIP: 24,\n};\n\n/**\n * Maps raw MediaPipe landmark data to a standardized rig pose.\n *\n * This is where the core mapping logic will reside. It will involve:\n * 1. Defining a mapping between MediaPipe landmarks and rig bones.\n * 2. Using vector math to calculate bone rotations from landmark positions.\n * 3. Comparing these rotations against a base \"T-pose\" to get the final rotation value.\n *\n * @param motionData The raw output from a MediaPipe Landmarker.\n * @returns A `RigPose` object representing the character's current pose.\n */\nexport const mapMotionDataToRigPose = (motionData: MotionData): RigPose | null => {\n  // TODO: Implement the mapping logic.\n  // For now, we'll just check if data exists.\n  if (!motionData?.landmarks || motionData.landmarks.length === 0) {\n    return null;\n  }\n\n  const rigPose: RigPose = {};\n\n  // --- PSEUDOCODE for mapping logic ---\n  // const worldLandmarks = motionData.worldLandmarks[0];\n  // if (worldLandmarks) {\n  //   const leftShoulder = worldLandmarks[11];\n  //   const leftElbow = worldLandmarks[13];\n  //   const leftWrist = worldLandmarks[15];\n  //   // const forearmRotation = calculateRotation(leftShoulder, leftElbow, leftWrist);\n  //   // rigPose['forearm.L'] = { rotation: forearmRotation };\n  // }\n  // --- END PSEUDOCODE ---\n\n  // For now, we'll return the raw data inside the 'data' property for debugging.\n  // This should be replaced with the actual RigPose object.\n  return { data: motionData };\n};"],"names":[],"mappings":";;;AAIA,kDAAkD;AAClD,MAAM,iBAAiB;IACrB,eAAe;IACf,gBAAgB;IAChB,YAAY;IACZ,aAAa;IACb,YAAY;IACZ,aAAa;IACb,UAAU;IACV,WAAW;AACb;AAaO,MAAM,yBAAyB,CAAC;IACrC,qCAAqC;IACrC,4CAA4C;IAC5C,IAAI,CAAC,YAAY,aAAa,WAAW,SAAS,CAAC,MAAM,KAAK,GAAG;QAC/D,OAAO;IACT;IAEA,MAAM,UAAmB,CAAC;IAE1B,uCAAuC;IACvC,uDAAuD;IACvD,wBAAwB;IACxB,6CAA6C;IAC7C,0CAA0C;IAC1C,0CAA0C;IAC1C,sFAAsF;IACtF,6DAA6D;IAC7D,IAAI;IACJ,yBAAyB;IAEzB,+EAA+E;IAC/E,0DAA0D;IAC1D,OAAO;QAAE,MAAM;IAAW;AAC5B","debugId":null}},
    {"offset": {"line": 639, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/services/motion/export.ts"],"sourcesContent":["import { MotionData } from '@/hooks/useMotionCapture';\nimport { CaptureType } from '@/components/MotionSelector';\nimport { createMotionDataPacket } from '@/lib/json-export';\n\n/**\n * Manages the WebSocket connection to a Blender tunnel for real-time data streaming.\n */\nexport class MotionTunnel {\n  private ws: WebSocket | null = null;\n\n  // Callbacks to update the UI based on connection status.\n  public onOpen: () => void = () => {};\n  public onClose: () => void = () => {};\n  public onError: (message: string) => void = () => {};\n\n  /**\n   * Establishes a connection to the WebSocket server at the given URL.\n   * @param url The wss:// or ws:// URL of the tunnel.\n   */\n  public connect(url: string): void {\n    if (this.ws && this.ws.readyState !== WebSocket.CLOSED) {\n      console.warn('A connection is already open. Disconnect first.');\n      return;\n    }\n\n    try {\n      this.ws = new WebSocket(url);\n\n      this.ws.onopen = () => {\n        console.log('Tunnel connection established.');\n        this.onOpen();\n      };\n\n      this.ws.onclose = () => {\n        console.log('Tunnel connection closed.');\n        this.onClose();\n        this.ws = null;\n      };\n\n      this.ws.onerror = (event) => {\n        console.error('Tunnel WebSocket error:', event);\n        this.onError('Connection failed. Check the URL and Blender addon.');\n        this.ws = null;\n      };\n    } catch (error) {\n      const message = error instanceof Error ? error.message : 'Invalid URL.';\n      this.onError(message);\n    }\n  }\n\n  /**\n   * Closes the active WebSocket connection.\n   */\n  public disconnect(): void {\n    this.ws?.close();\n  }\n\n  /**\n   * Sends motion data through the open WebSocket connection.\n   */\n  public sendData(motionData: MotionData, captureType: CaptureType): void {\n    if (this.ws?.readyState === WebSocket.OPEN) {\n      const payload = createMotionDataPacket(motionData, captureType);\n      this.ws.send(JSON.stringify(payload));\n    }\n  }\n}"],"names":[],"mappings":";;;AAEA;;AAKO,MAAM;IACH,KAAuB,KAAK;IAEpC,yDAAyD;IAClD,SAAqB,KAAO,EAAE;IAC9B,UAAsB,KAAO,EAAE;IAC/B,UAAqC,KAAO,EAAE;IAErD;;;GAGC,GACD,AAAO,QAAQ,GAAW,EAAQ;QAChC,IAAI,IAAI,CAAC,EAAE,IAAI,IAAI,CAAC,EAAE,CAAC,UAAU,KAAK,UAAU,MAAM,EAAE;YACtD,QAAQ,IAAI,CAAC;YACb;QACF;QAEA,IAAI;YACF,IAAI,CAAC,EAAE,GAAG,IAAI,UAAU;YAExB,IAAI,CAAC,EAAE,CAAC,MAAM,GAAG;gBACf,QAAQ,GAAG,CAAC;gBACZ,IAAI,CAAC,MAAM;YACb;YAEA,IAAI,CAAC,EAAE,CAAC,OAAO,GAAG;gBAChB,QAAQ,GAAG,CAAC;gBACZ,IAAI,CAAC,OAAO;gBACZ,IAAI,CAAC,EAAE,GAAG;YACZ;YAEA,IAAI,CAAC,EAAE,CAAC,OAAO,GAAG,CAAC;gBACjB,QAAQ,KAAK,CAAC,2BAA2B;gBACzC,IAAI,CAAC,OAAO,CAAC;gBACb,IAAI,CAAC,EAAE,GAAG;YACZ;QACF,EAAE,OAAO,OAAO;YACd,MAAM,UAAU,iBAAiB,QAAQ,MAAM,OAAO,GAAG;YACzD,IAAI,CAAC,OAAO,CAAC;QACf;IACF;IAEA;;GAEC,GACD,AAAO,aAAmB;QACxB,IAAI,CAAC,EAAE,EAAE;IACX;IAEA;;GAEC,GACD,AAAO,SAAS,UAAsB,EAAE,WAAwB,EAAQ;QACtE,IAAI,IAAI,CAAC,EAAE,EAAE,eAAe,UAAU,IAAI,EAAE;YAC1C,MAAM,UAAU,CAAA,GAAA,qHAAA,CAAA,yBAAsB,AAAD,EAAE,YAAY;YACnD,IAAI,CAAC,EAAE,CAAC,IAAI,CAAC,KAAK,SAAS,CAAC;QAC9B;IACF;AACF","debugId":null}},
    {"offset": {"line": 697, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/components/CharacterModel.tsx"],"sourcesContent":["'use client';\n\nimport React, { useEffect, useRef } from 'react';\nimport { useGLTF } from '@react-three/drei';\nimport { useFrame } from '@react-three/fiber';\nimport * as THREE from 'three';\nimport { RigPose } from '@/types/rig';\n\ninterface CharacterModelProps {\n  pose: RigPose | null;\n  onTposeReady: (tPose: RigPose) => void;\n  debugMode?: boolean;\n}\n\nexport const CharacterModel: React.FC<CharacterModelProps> = ({ pose, onTposeReady, debugMode = false }) => {\n  // Load the GLB model from the public directory\n  const { scene } = useGLTF('/models/metarig.glb');\n  const tPoseCaptured = useRef(false);\n  const boneAxesHelpers = useRef<Record<string, THREE.AxesHelper>>({});\n\n  // Capture the initial T-Pose of the model once it's loaded.\n  useEffect(() => {\n    if (scene && !tPoseCaptured.current) {\n      const tPose: RigPose = {};\n      scene.traverse((object) => {\n        if (object instanceof THREE.Bone) {\n          // Store the initial rotation of each bone\n          tPose[object.name] = {\n            rotation: object.quaternion.toArray() as [number, number, number, number],\n          };\n        }\n      });\n      onTposeReady(tPose);\n      tPoseCaptured.current = true;\n    }\n  }, [scene, onTposeReady]);\n  \n  // On every frame, apply the pose data to the bones\n  useFrame(() => {\n    if (pose) {\n      // Traverse the scene to find all bones\n      scene.traverse((object) => {\n        if (object instanceof THREE.Bone) {\n          // Check if the current bone has a corresponding entry in the pose data\n          const bonePose = pose[object.name];\n          if (bonePose) {\n            const { rotation } = bonePose;\n            // Apply the rotation.\n            object.quaternion.fromArray(rotation);\n\n            // Add or remove debug axes\n            if (debugMode) {\n              if (!boneAxesHelpers.current[object.name]) {\n                const helper = new THREE.AxesHelper(0.2); // 20cm axes\n                boneAxesHelpers.current[object.name] = helper;\n                object.add(helper);\n              }\n            } else if (boneAxesHelpers.current[object.name]) {\n              object.remove(boneAxesHelpers.current[object.name]);\n              delete boneAxesHelpers.current[object.name];\n            }\n          }\n        }\n      });\n    }\n  });\n\n  // The primitive object is a way to render a pre-existing Three.js object\n  return <primitive object={scene} />;\n};\n\n// Preload the model so it's ready when the component mounts for a better user experience.\nuseGLTF.preload('/models/metarig.glb');"],"names":[],"mappings":";;;;AAEA;AACA;AACA;AACA;AALA;;;;;;AAcO,MAAM,iBAAgD,CAAC,EAAE,IAAI,EAAE,YAAY,EAAE,YAAY,KAAK,EAAE;IACrG,+CAA+C;IAC/C,MAAM,EAAE,KAAK,EAAE,GAAG,CAAA,GAAA,wJAAA,CAAA,UAAO,AAAD,EAAE;IAC1B,MAAM,gBAAgB,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAAE;IAC7B,MAAM,kBAAkB,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAAoC,CAAC;IAElE,4DAA4D;IAC5D,CAAA,GAAA,qMAAA,CAAA,YAAS,AAAD,EAAE;QACR,IAAI,SAAS,CAAC,cAAc,OAAO,EAAE;YACnC,MAAM,QAAiB,CAAC;YACxB,MAAM,QAAQ,CAAC,CAAC;gBACd,IAAI,kBAAkB,+IAAA,CAAA,OAAU,EAAE;oBAChC,0CAA0C;oBAC1C,KAAK,CAAC,OAAO,IAAI,CAAC,GAAG;wBACnB,UAAU,OAAO,UAAU,CAAC,OAAO;oBACrC;gBACF;YACF;YACA,aAAa;YACb,cAAc,OAAO,GAAG;QAC1B;IACF,GAAG;QAAC;QAAO;KAAa;IAExB,mDAAmD;IACnD,CAAA,GAAA,+MAAA,CAAA,WAAQ,AAAD,EAAE;QACP,IAAI,MAAM;YACR,uCAAuC;YACvC,MAAM,QAAQ,CAAC,CAAC;gBACd,IAAI,kBAAkB,+IAAA,CAAA,OAAU,EAAE;oBAChC,uEAAuE;oBACvE,MAAM,WAAW,IAAI,CAAC,OAAO,IAAI,CAAC;oBAClC,IAAI,UAAU;wBACZ,MAAM,EAAE,QAAQ,EAAE,GAAG;wBACrB,sBAAsB;wBACtB,OAAO,UAAU,CAAC,SAAS,CAAC;wBAE5B,2BAA2B;wBAC3B,IAAI,WAAW;4BACb,IAAI,CAAC,gBAAgB,OAAO,CAAC,OAAO,IAAI,CAAC,EAAE;gCACzC,MAAM,SAAS,IAAI,+IAAA,CAAA,aAAgB,CAAC,MAAM,YAAY;gCACtD,gBAAgB,OAAO,CAAC,OAAO,IAAI,CAAC,GAAG;gCACvC,OAAO,GAAG,CAAC;4BACb;wBACF,OAAO,IAAI,gBAAgB,OAAO,CAAC,OAAO,IAAI,CAAC,EAAE;4BAC/C,OAAO,MAAM,CAAC,gBAAgB,OAAO,CAAC,OAAO,IAAI,CAAC;4BAClD,OAAO,gBAAgB,OAAO,CAAC,OAAO,IAAI,CAAC;wBAC7C;oBACF;gBACF;YACF;QACF;IACF;IAEA,yEAAyE;IACzE,qBAAO,8OAAC;QAAU,QAAQ;;;;;;AAC5B;AAEA,0FAA0F;AAC1F,wJAAA,CAAA,UAAO,CAAC,OAAO,CAAC","debugId":null}},
    {"offset": {"line": 778, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/components/CharacterViewer.tsx"],"sourcesContent":["'use client';\n\nimport React, { Suspense } from 'react';\nimport { Canvas } from '@react-three/fiber';\nimport { OrbitControls } from '@react-three/drei';\nimport { CharacterModel } from './CharacterModel';\nimport { RigPose } from '@/types/rig';\n\n/**\n * A 3D viewer component to display the character model and its animated pose.\n * This component uses react-three-fiber to render a Three.js scene.\n */\nconst CharacterViewer: React.FC<{\n  pose: RigPose | null;\n  onTposeReady: (tPose: RigPose) => void;\n  debugMode?: boolean;\n}> = ({ pose, onTposeReady, debugMode = false }) => {\n  return (\n    <div className=\"w-full h-full bg-neutral-200 dark:bg-neutral-800 rounded-lg\">\n      <Canvas camera={{ position: [0, 1, 2.5], fov: 50 }}>\n        <ambientLight intensity={0.5} />\n        <directionalLight position={[5, 5, 5]} intensity={1} />\n        <OrbitControls />\n        {debugMode && <axesHelper args={[1]} />} {/* World axes */}\n        <Suspense fallback={null}>\n          <CharacterModel pose={pose} onTposeReady={onTposeReady} debugMode={debugMode} />\n        </Suspense>\n      </Canvas>\n    </div>\n  );\n};\n\nexport default CharacterViewer;"],"names":[],"mappings":";;;;AAEA;AACA;AACA;AACA;AALA;;;;;;AAQA;;;CAGC,GACD,MAAM,kBAID,CAAC,EAAE,IAAI,EAAE,YAAY,EAAE,YAAY,KAAK,EAAE;IAC7C,qBACE,8OAAC;QAAI,WAAU;kBACb,cAAA,8OAAC,mMAAA,CAAA,SAAM;YAAC,QAAQ;gBAAE,UAAU;oBAAC;oBAAG;oBAAG;iBAAI;gBAAE,KAAK;YAAG;;8BAC/C,8OAAC;oBAAa,WAAW;;;;;;8BACzB,8OAAC;oBAAiB,UAAU;wBAAC;wBAAG;wBAAG;qBAAE;oBAAE,WAAW;;;;;;8BAClD,8OAAC,iKAAA,CAAA,gBAAa;;;;;gBACb,2BAAa,8OAAC;oBAAW,MAAM;wBAAC;qBAAE;;;;;;gBAAK;8BACxC,8OAAC,qMAAA,CAAA,WAAQ;oBAAC,UAAU;8BAClB,cAAA,8OAAC,6HAAA,CAAA,iBAAc;wBAAC,MAAM;wBAAM,cAAc;wBAAc,WAAW;;;;;;;;;;;;;;;;;;;;;;AAK7E;uCAEe","debugId":null}},
    {"offset": {"line": 875, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/components/InputSelector.tsx"],"sourcesContent":["import React from 'react';\n\n/**\n * Defines the possible types of input sources for character control.\n */\nexport type InputSourceType = 'webcam' | 'video';\n\n/**\n * Props for the InputSelector component.\n */\ninterface InputSelectorProps {\n  /**\n   * Callback function that is invoked when a new input source is selected.\n   * @param source The newly selected input source type.\n   */\n  onSourceSelect: (source: InputSourceType) => void;\n  /**\n   * The currently active input source. This is used to highlight the active selection.\n   */\n  currentSource: InputSourceType | null;\n}\n\n/**\n * A component that allows users to select an input source (e.g., Webcam, Video file).\n * It displays a set of buttons for each available source and highlights the current selection.\n */\nconst InputSelector: React.FC<InputSelectorProps> = ({ onSourceSelect, currentSource }) => {\n  const sources: InputSourceType[] = ['webcam', 'video'];\n\n  return (\n    <div className=\"p-4 bg-gray-800 rounded-lg shadow-md\">\n      <h2 className=\"text-lg font-semibold text-white mb-3\">Select Input Source</h2>\n      <div className=\"flex space-x-2\">\n        {sources.map((source) => (\n          <button key={source} onClick={() => onSourceSelect(source)} className={`px-4 py-2 rounded-md text-sm font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-gray-800 focus:ring-blue-500 ${currentSource === source ? 'bg-blue-600 text-white' : 'bg-gray-700 text-gray-300 hover:bg-gray-600'}`}>\n            {source.charAt(0).toUpperCase() + source.slice(1)}\n          </button>\n        ))}\n      </div>\n    </div>\n  );\n};\n\nexport default InputSelector;\n\n"],"names":[],"mappings":";;;;;AAsBA;;;CAGC,GACD,MAAM,gBAA8C,CAAC,EAAE,cAAc,EAAE,aAAa,EAAE;IACpF,MAAM,UAA6B;QAAC;QAAU;KAAQ;IAEtD,qBACE,8OAAC;QAAI,WAAU;;0BACb,8OAAC;gBAAG,WAAU;0BAAwC;;;;;;0BACtD,8OAAC;gBAAI,WAAU;0BACZ,QAAQ,GAAG,CAAC,CAAC,uBACZ,8OAAC;wBAAoB,SAAS,IAAM,eAAe;wBAAS,WAAW,CAAC,8JAA8J,EAAE,kBAAkB,SAAS,2BAA2B,+CAA+C;kCAC1U,OAAO,MAAM,CAAC,GAAG,WAAW,KAAK,OAAO,KAAK,CAAC;uBADpC;;;;;;;;;;;;;;;;AAOvB;uCAEe","debugId":null}},
    {"offset": {"line": 927, "column": 0}, "map": {"version":3,"sources":["file:///Volumes/CMPRO128GB/AGI_projects/maiChuong_github/cmpro-gaomotion/app/page.tsx"],"sourcesContent":["'use client';\n\nimport { useState, useRef, useEffect } from 'react';\nimport MotionSelector, { CaptureType } from '@/components/MotionSelector';\nimport TunnelPairer, { TunnelStatus } from '@/components/TunnelPairer';\nimport { useMotionCapture, MotionData } from '@/hooks/useMotionCapture';\nimport { downloadMotionDataAsJson } from '@/lib/json-export';\nimport RigMapper from '@/components/RigMapper';\nimport { mapMotionDataToRigPose } from '@/services/motion/mapper';\nimport { MotionTunnel } from '@/services/motion/export';\nimport CharacterViewer from '@/components/CharacterViewer';\nimport { RigPose } from '@/types/rig';\nimport InputSelector, { InputSourceType } from '@/components/InputSelector';\n\n/**\n * A dedicated component for the live capture view.\n * This ensures that the useMotionCapture hook is not called conditionally.\n */\nconst CaptureView = ({\n  captureType,\n  onBack,\n}: {\n  captureType: CaptureType;\n  onBack: () => void;\n}) => {\n  const motionTunnelRef = useRef<MotionTunnel | null>(null);\n\n  // Use a ref to store the latest motion data to avoid re-renders on every frame.\n  const motionDataRef = useRef<MotionData | null>(null);\n  // Use state to track if any data has been captured at all, to enable/disable export buttons.\n  const [hasCapturedData, setHasCapturedData] = useState(false);\n  const [visualizedPose, setVisualizedPose] = useState<RigPose | null>(null);\n  const [tPose, setTpose] = useState<RigPose | null>(null);\n  const [debugMode, setDebugMode] = useState(false);\n  const [inputSource, setInputSource] = useState<InputSourceType>('webcam');\n  const [videoUrl, setVideoUrl] = useState<string | undefined>();\n\n  const {\n    videoRef,\n    canvasRef,\n    isCameraOn,\n    isProcessing,\n    error,\n    startCapture,\n    stopCapture,\n  } = useMotionCapture({\n    inputSource,\n    videoUrl,\n    captureType,\n    onData: (data) => {\n      // 1. Map the raw data to a rig pose\n      const rigPose = mapMotionDataToRigPose(data, tPose);\n      if (!rigPose) return;\n\n      motionDataRef.current = rigPose; // Store the mapped pose for export/tunnel\n      setVisualizedPose(rigPose); // Update state for visualization\n      if (!hasCapturedData) setHasCapturedData(true);\n      motionTunnelRef.current?.sendData(rigPose, captureType); // Send the mapped pose\n    },\n  });\n\n  const [tunnelStatus, setTunnelStatus] = useState<TunnelStatus>('disconnected');\n  const [tunnelError, setTunnelError] = useState<string | null>(null);\n\n  const handleConnect = (url: string) => {\n    if (!motionTunnelRef.current) {\n      motionTunnelRef.current = new MotionTunnel();\n    }\n\n    setTunnelStatus('connecting');\n    setTunnelError(null);\n\n    motionTunnelRef.current.onOpen = () => setTunnelStatus('connected');\n    motionTunnelRef.current.onClose = () => setTunnelStatus('disconnected');\n    motionTunnelRef.current.onError = (message) => {\n      setTunnelStatus('error');\n      setTunnelError(message);\n    };\n\n    motionTunnelRef.current.connect(url);\n  };\n\n  const handleDisconnect = () => {\n    motionTunnelRef.current?.disconnect();\n  };\n\n  // Effect to ensure the tunnel is disconnected on component unmount.\n  useEffect(() => {\n    return () => {\n      motionTunnelRef.current?.disconnect();\n    };\n  }, []);\n\n  const handleSourceChange = (sourceType: InputSourceType, url?: string) => {\n    stopCapture();\n    setInputSource(sourceType);\n    setVideoUrl(url);\n  };\n\n  return (\n    <div className=\"w-full max-w-4xl flex flex-col items-center\">\n      <div className=\"w-full flex justify-between items-center mb-4\">\n        <button\n          onClick={onBack}\n          className=\"px-4 py-2 border rounded-lg hover:bg-neutral-100 dark:hover:bg-neutral-800/30 transition-colors\"\n        >\n          &larr; Back\n        </button>\n        <h1 className=\"text-2xl font-bold capitalize\">{captureType} Capture</h1>\n        <div className=\"w-24\" /> {/* Spacer */}\n      </div>\n\n      <div className=\"w-full mb-4\">\n        <InputSelector onSourceChange={handleSourceChange} />\n      </div>\n\n      <div className=\"grid w-full grid-cols-1 md:grid-cols-2 gap-4 aspect-video\">\n        {/* 2D Video Feed */}\n        <div className=\"relative w-full h-full bg-black rounded-lg overflow-hidden shadow-lg\">\n          <video ref={videoRef} className=\"w-full h-full\" autoPlay playsInline />\n          <canvas\n            ref={canvasRef}\n            className=\"absolute top-0 left-0 w-full h-full\"\n          />\n        </div>\n        {/* 3D Character Viewer */}\n        <CharacterViewer pose={visualizedPose} onTposeReady={setTpose} debugMode={debugMode} />\n      </div>\n\n      <div className=\"flex flex-wrap items-center justify-center gap-4 mt-4\">\n        <button\n          onClick={startCapture}\n          disabled={isCameraOn || isProcessing}\n          className=\"px-4 py-2 bg-blue-600 text-white rounded-lg disabled:bg-gray-400 transition-colors\"\n        >\n          {isProcessing ? 'Initializing...' : 'Start Capture'}\n        </button>\n        <button\n          onClick={stopCapture}\n          disabled={!isCameraOn}\n          className=\"px-4 py-2 bg-red-600 text-white rounded-lg disabled:bg-gray-400 transition-colors\"\n        >\n          Stop Capture\n        </button>\n        <button\n          onClick={() => {\n            if (motionDataRef.current) {\n              downloadMotionDataAsJson(motionDataRef.current, captureType);\n            }\n          }}\n          disabled={!hasCapturedData}\n          className=\"px-4 py-2 bg-green-600 text-white rounded-lg disabled:bg-gray-400 transition-colors\"\n          title=\"Download the last captured frame as a JSON file.\"\n        >\n          Export JSON\n        </button>\n        <label className=\"flex items-center space-x-2 cursor-pointer p-2 rounded-lg bg-neutral-100 dark:bg-neutral-800\">\n          <input\n            type=\"checkbox\"\n            checked={debugMode}\n            onChange={(e) => setDebugMode(e.target.checked)}\n            className=\"form-checkbox\"\n          />\n          <span className=\"text-sm\">Debug Mode</span>\n        </label>\n      </div>\n      {error && <p className=\"mt-4 text-red-500\">{error}</p>}\n\n      <div className=\"mt-8 grid w-full grid-cols-1 gap-8 md:grid-cols-2\">\n        <TunnelPairer\n          status={tunnelStatus}\n          error={tunnelError}\n          onConnect={handleConnect}\n          onDisconnect={handleDisconnect}\n        />\n        <RigMapper pose={visualizedPose} />\n      </div>\n    </div>\n  );\n};\n\nexport default function Home() {\n  const [captureType, setCaptureType] = useState<CaptureType | null>(null);\n\n  return (\n    <main className=\"flex min-h-screen flex-col items-center justify-center p-4 md:p-8\">\n      {!captureType ? (\n        <MotionSelector onSelect={setCaptureType} />\n      ) : (\n        <CaptureView captureType={captureType} onBack={() => setCaptureType(null)} />\n      )}\n    </main>\n  );\n}\n"],"names":[],"mappings":";;;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAZA;;;;;;;;;;;;AAcA;;;CAGC,GACD,MAAM,cAAc,CAAC,EACnB,WAAW,EACX,MAAM,EAIP;IACC,MAAM,kBAAkB,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAAuB;IAEpD,gFAAgF;IAChF,MAAM,gBAAgB,CAAA,GAAA,qMAAA,CAAA,SAAM,AAAD,EAAqB;IAChD,6FAA6F;IAC7F,MAAM,CAAC,iBAAiB,mBAAmB,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAE;IACvD,MAAM,CAAC,gBAAgB,kBAAkB,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAkB;IACrE,MAAM,CAAC,OAAO,SAAS,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAkB;IACnD,MAAM,CAAC,WAAW,aAAa,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAE;IAC3C,MAAM,CAAC,aAAa,eAAe,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAmB;IAChE,MAAM,CAAC,UAAU,YAAY,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD;IAEvC,MAAM,EACJ,QAAQ,EACR,SAAS,EACT,UAAU,EACV,YAAY,EACZ,KAAK,EACL,YAAY,EACZ,WAAW,EACZ,GAAG,CAAA,GAAA,yHAAA,CAAA,mBAAgB,AAAD,EAAE;QACnB;QACA;QACA;QACA,QAAQ,CAAC;YACP,oCAAoC;YACpC,MAAM,UAAU,CAAA,GAAA,4HAAA,CAAA,yBAAsB,AAAD,EAAE,MAAM;YAC7C,IAAI,CAAC,SAAS;YAEd,cAAc,OAAO,GAAG,SAAS,0CAA0C;YAC3E,kBAAkB,UAAU,iCAAiC;YAC7D,IAAI,CAAC,iBAAiB,mBAAmB;YACzC,gBAAgB,OAAO,EAAE,SAAS,SAAS,cAAc,uBAAuB;QAClF;IACF;IAEA,MAAM,CAAC,cAAc,gBAAgB,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAgB;IAC/D,MAAM,CAAC,aAAa,eAAe,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAiB;IAE9D,MAAM,gBAAgB,CAAC;QACrB,IAAI,CAAC,gBAAgB,OAAO,EAAE;YAC5B,gBAAgB,OAAO,GAAG,IAAI,4HAAA,CAAA,eAAY;QAC5C;QAEA,gBAAgB;QAChB,eAAe;QAEf,gBAAgB,OAAO,CAAC,MAAM,GAAG,IAAM,gBAAgB;QACvD,gBAAgB,OAAO,CAAC,OAAO,GAAG,IAAM,gBAAgB;QACxD,gBAAgB,OAAO,CAAC,OAAO,GAAG,CAAC;YACjC,gBAAgB;YAChB,eAAe;QACjB;QAEA,gBAAgB,OAAO,CAAC,OAAO,CAAC;IAClC;IAEA,MAAM,mBAAmB;QACvB,gBAAgB,OAAO,EAAE;IAC3B;IAEA,oEAAoE;IACpE,CAAA,GAAA,qMAAA,CAAA,YAAS,AAAD,EAAE;QACR,OAAO;YACL,gBAAgB,OAAO,EAAE;QAC3B;IACF,GAAG,EAAE;IAEL,MAAM,qBAAqB,CAAC,YAA6B;QACvD;QACA,eAAe;QACf,YAAY;IACd;IAEA,qBACE,8OAAC;QAAI,WAAU;;0BACb,8OAAC;gBAAI,WAAU;;kCACb,8OAAC;wBACC,SAAS;wBACT,WAAU;kCACX;;;;;;kCAGD,8OAAC;wBAAG,WAAU;;4BAAiC;4BAAY;;;;;;;kCAC3D,8OAAC;wBAAI,WAAU;;;;;;oBAAS;;;;;;;0BAG1B,8OAAC;gBAAI,WAAU;0BACb,cAAA,8OAAC,4HAAA,CAAA,UAAa;oBAAC,gBAAgB;;;;;;;;;;;0BAGjC,8OAAC;gBAAI,WAAU;;kCAEb,8OAAC;wBAAI,WAAU;;0CACb,8OAAC;gCAAM,KAAK;gCAAU,WAAU;gCAAgB,QAAQ;gCAAC,WAAW;;;;;;0CACpE,8OAAC;gCACC,KAAK;gCACL,WAAU;;;;;;;;;;;;kCAId,8OAAC,8HAAA,CAAA,UAAe;wBAAC,MAAM;wBAAgB,cAAc;wBAAU,WAAW;;;;;;;;;;;;0BAG5E,8OAAC;gBAAI,WAAU;;kCACb,8OAAC;wBACC,SAAS;wBACT,UAAU,cAAc;wBACxB,WAAU;kCAET,eAAe,oBAAoB;;;;;;kCAEtC,8OAAC;wBACC,SAAS;wBACT,UAAU,CAAC;wBACX,WAAU;kCACX;;;;;;kCAGD,8OAAC;wBACC,SAAS;4BACP,IAAI,cAAc,OAAO,EAAE;gCACzB,CAAA,GAAA,qHAAA,CAAA,2BAAwB,AAAD,EAAE,cAAc,OAAO,EAAE;4BAClD;wBACF;wBACA,UAAU,CAAC;wBACX,WAAU;wBACV,OAAM;kCACP;;;;;;kCAGD,8OAAC;wBAAM,WAAU;;0CACf,8OAAC;gCACC,MAAK;gCACL,SAAS;gCACT,UAAU,CAAC,IAAM,aAAa,EAAE,MAAM,CAAC,OAAO;gCAC9C,WAAU;;;;;;0CAEZ,8OAAC;gCAAK,WAAU;0CAAU;;;;;;;;;;;;;;;;;;YAG7B,uBAAS,8OAAC;gBAAE,WAAU;0BAAqB;;;;;;0BAE5C,8OAAC;gBAAI,WAAU;;kCACb,8OAAC,2HAAA,CAAA,UAAY;wBACX,QAAQ;wBACR,OAAO;wBACP,WAAW;wBACX,cAAc;;;;;;kCAEhB,8OAAC,wHAAA,CAAA,UAAS;wBAAC,MAAM;;;;;;;;;;;;;;;;;;AAIzB;AAEe,SAAS;IACtB,MAAM,CAAC,aAAa,eAAe,GAAG,CAAA,GAAA,qMAAA,CAAA,WAAQ,AAAD,EAAsB;IAEnE,qBACE,8OAAC;QAAK,WAAU;kBACb,CAAC,4BACA,8OAAC,6HAAA,CAAA,UAAc;YAAC,UAAU;;;;;iCAE1B,8OAAC;YAAY,aAAa;YAAa,QAAQ,IAAM,eAAe;;;;;;;;;;;AAI5E","debugId":null}}]
}